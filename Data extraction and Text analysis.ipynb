{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4411220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67bfe76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\psykid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\psykid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd2190ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3        40  https://insights.blackcoffer.com/will-machine-...\n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110     147  https://insights.blackcoffer.com/the-future-of...\n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112     149  https://insights.blackcoffer.com/business-anal...\n",
       "113     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read input data into a pandas DataFrame\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\Input.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f44d3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract article content and title\n",
    "def extract_info(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    article = soup.find('div', class_='td-post-content')\n",
    "    title = soup.find('h1', class_='entry-title')\n",
    "    \n",
    "    if article is None and title is None:\n",
    "        title = soup.find('h1', class_='tdb-title-text')\n",
    "        article = soup.find('div', class_='td-ss-main-content')\n",
    "    elif article is None:\n",
    "        article = soup.find('div', class_='td-ss-main-content')\n",
    "    elif title is None:\n",
    "        title = soup.find('h1', class_='tdb-title-text')\n",
    "    \n",
    "    if article is None or title is None:\n",
    "        return None, None\n",
    "    \n",
    "    return article.get_text().strip(), title.get_text().strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loop through each URL in the DataFrame and extract the article and title\n",
    "data = []\n",
    "for url in df['URL']:\n",
    "    article, title = extract_info(url)\n",
    "    data.append({'Title': title, 'Article': article})\n",
    "    \n",
    "# create a new DataFrame with the extracted data and save to a CSV file\n",
    "df_cleaned = pd.DataFrame(data)\n",
    "df_cleaned.to_csv('output2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9db0e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI in healthcare to Improve Patient OutcomesIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will AI Replace Us or Work With Us?“Machine in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Blockchain for PaymentsReconciling with the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>The future of InvestingWhat Is an Investment?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Big Data Analytics in HealthcareQuality and af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Business Analytics In The Healthcare IndustryA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    AI in healthcare to Improve Patient OutcomesIn...\n",
       "1    What if the Creation is Taking Over the Creato...\n",
       "2    What Jobs Will Robots Take From Humans in The ...\n",
       "3    Will Machine Replace The Human in the Future o...\n",
       "4    Will AI Replace Us or Work With Us?“Machine in...\n",
       "..                                                 ...\n",
       "109  Blockchain for PaymentsReconciling with the fi...\n",
       "110  The future of InvestingWhat Is an Investment?\\...\n",
       "111  Big Data Analytics in HealthcareQuality and af...\n",
       "112  Business Analytics In The Healthcare IndustryA...\n",
       "113  Challenges and Opportunities of Big Data in He...\n",
       "\n",
       "[114 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3=pd.read_csv('output2.csv')\n",
    "d3['text']=d3['Title']+d3['Article']\n",
    "d3.drop(['Title','Article'],axis=1,inplace=True)\n",
    "d3=d3.astype(str)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63ebe151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82a8f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.dropna(inplace=True)\n",
    "d3.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1d45b",
   "metadata": {},
   "source": [
    "In the provided url inputs,3 of them are invalid urls and these pages doesn't exist,includes https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future [url ids:7], https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future  [url ids:20],  and https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology  [url id:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43662f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14099"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Stopwords\n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_Auditor.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_Auditor= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_Auditor= [line.strip() for line in StopWords_Auditor]\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_Currencies.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_Currencies= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_Currencies= [line.strip() for line in StopWords_Currencies]\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_DatesandNumbers.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_DatesandNumbers= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_DatesandNumbers= [line.strip() for line in StopWords_DatesandNumbers]\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_Generic.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_Generic= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_Generic= [line.strip() for line in StopWords_Generic]\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_GenericLong.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_GenericLong= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_GenericLLong= [line.strip() for line in StopWords_GenericLong]\n",
    "    # Remove the \\n characters from each word using a loop\n",
    "    for i in range(len(StopWords_GenericLong)):\n",
    "        StopWords_GenericLong[i] = StopWords_GenericLong[i].strip()\n",
    "        \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_Geographic.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_Geographic= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_Geographic= [line.strip() for line in StopWords_Geographic]\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\psykid\\\\Desktop\\\\blackcoffer\\\\StopWords\\\\StopWords_Names.txt\", 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    StopWords_Names= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    StopWords_Names= [line.strip() for line in StopWords_Names]\n",
    "    \n",
    "    \n",
    "all_stop_words=StopWords_Currencies+StopWords_DatesandNumbers+StopWords_Generic+StopWords_GenericLong+StopWords_Geographic+StopWords_Names\n",
    "len(all_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c9c8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text) # Remove text between square brackets\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
    "    text = re.sub('[‘’“”…]', '', text) # Remove special characters\n",
    "    text = ' '.join([word for word in text.split() if word not in all_stop_words]) # Remove stop words\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f24fa8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the positive score\n",
    "def positive_score(tokens, pos_dict):\n",
    "    return sum(1 for token in tokens if token.lower() in pos_dict)\n",
    "\n",
    "# Define a function to calculate the negative score\n",
    "def negative_score(tokens, neg_dict):\n",
    "    return sum(1 for token in tokens if token.lower() in neg_dict)\n",
    "\n",
    "# Define a function to calculate the polarity score\n",
    "def pol_score(pos_score, neg_score):\n",
    "    return (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
    "\n",
    "# Define a function to calculate the subjectivity score\n",
    "def subjectivity_score(pos_score, neg_score, clean_word_length):\n",
    "    return (pos_score + neg_score) /(clean_word_length + 0.000001)\n",
    "\n",
    "# Define a function to calculate the average sentence length\n",
    "def avg_sent_len(sentences,clean_word_length):\n",
    "    return clean_word_length /sentences\n",
    "\n",
    "#define a function to calculate percentage of complex words\n",
    "def percentage_complex_words(tokens,clean_word_length):\n",
    "    complex_wordcount=count_complex_words(tokens)\n",
    "    return complex_words /clean_word_length\n",
    "\n",
    "#define a function to calculate complex words\n",
    "def count_complex_words(text):\n",
    "    # Load the CMU Pronouncing Dictionary to count syllables\n",
    "    d = cmudict.dict()\n",
    "    \n",
    "    complex_words = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            # Get the number of syllables for the current word\n",
    "            num_syllables = [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "        except KeyError:\n",
    "            num_syllables = 0\n",
    "        \n",
    "        # Check if the word has more than two syllables\n",
    "        if num_syllables > 2:\n",
    "            complex_words += 1\n",
    "    \n",
    "    return complex_words\n",
    "\n",
    "# Define a function to calculate the fog index\n",
    "def f_ind(avg_sentence_length, percentage_complex_words):\n",
    "    return 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "\n",
    "# Define a function to calculate the average number of words per sentence\n",
    "def avg_words_per_sent(clean_words, sentences):\n",
    "    return clean_words /sentences\n",
    "\n",
    "\n",
    "# Define a function to calculate the total word count\n",
    "def w_count(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return len([token for token in tokens if token.lower() not in stop_words and token.lower() not in string.punctuation])\n",
    "\n",
    "def syllable_count(word):\n",
    "    syllable = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if not isinstance(word, str):\n",
    "        word = str(word)\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    if len(word) > 0:\n",
    "        if word[0] in vowels:\n",
    "            syllable += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index-1] not in vowels:\n",
    "                syllable += 1\n",
    "        if word.endswith('es') or word.endswith('ed'):\n",
    "            syllable -= 1\n",
    "    return syllable if syllable > 0 else 1\n",
    "\n",
    "\n",
    "# Define a function to calculate the syllables per word\n",
    "def syllableperword(tokens):\n",
    "    return sum(syllable_count(token.lower()) for token in tokens) / len(tokens)\n",
    "\n",
    "# Define a function to calculate the personal pronoun count\n",
    "def pronouns_count(text):\n",
    "    import re\n",
    "    pronoun_counts = {\n",
    "        \"I\": 0,\n",
    "        \"we\": 0,\n",
    "        \"my\": 0,\n",
    "        \"ours\": 0,\n",
    "        \"us\": 0\n",
    "    }\n",
    "\n",
    "    for pronoun in pronoun_counts:\n",
    "        # Use word boundaries to avoid matching \"US\"\n",
    "        regex = r\"\\b\" + pronoun + r\"\\b\"\n",
    "        pronoun_counts[pronoun] = len(re.findall(regex, text))\n",
    "\n",
    "    total_pronouns = sum(pronoun_counts.values())\n",
    "    return total_pronouns\n",
    "\n",
    "def avg_word_len(text):\n",
    "    avg_word_lengths = []\n",
    "\n",
    "    for text in txt:\n",
    "        total_length = 0\n",
    "        word_count = 0\n",
    "        words = text.split()\n",
    "    \n",
    "        for word in words:\n",
    "            total_length += len(word)\n",
    "            word_count += 1\n",
    "        \n",
    "        avg_word_length = total_length / word_count\n",
    "        avg_word_lengths.append(avg_word_length)\n",
    "\n",
    "    return sum(avg_word_lengths) / len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "317baae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Dictionary\n",
    "with open('positive-words.txt', 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    pos_dict= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    pos_dict = [line.strip() for line in pos_dict]\n",
    "    \n",
    "\n",
    "#Negative Dictionary\n",
    "\n",
    "with open('negative-words.txt', 'r') as f:\n",
    "\n",
    "    # Read the contents of the file into a list\n",
    "    neg_dict= f.readlines()\n",
    "    \n",
    "    # Remove newline characters from each line\n",
    "    neg_dict = [line.strip() for line in neg_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "63ab7256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>negative score</th>\n",
       "      <th>polarity score</th>\n",
       "      <th>subjectivity score</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>Percentage of Complex_words</th>\n",
       "      <th>fog index</th>\n",
       "      <th>Average Number of Words Per Sentence</th>\n",
       "      <th>complex words</th>\n",
       "      <th>word count</th>\n",
       "      <th>syllables per word</th>\n",
       "      <th>personal pronouns count</th>\n",
       "      <th>average word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI in healthcare to Improve Patient OutcomesIn...</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>8.230588</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>379</td>\n",
       "      <td>1020</td>\n",
       "      <td>2.496078</td>\n",
       "      <td>1</td>\n",
       "      <td>5.801782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.159278</td>\n",
       "      <td>9.515625</td>\n",
       "      <td>0.622332</td>\n",
       "      <td>4.055183</td>\n",
       "      <td>9.515625</td>\n",
       "      <td>190</td>\n",
       "      <td>609</td>\n",
       "      <td>2.215107</td>\n",
       "      <td>6</td>\n",
       "      <td>5.007047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.116705</td>\n",
       "      <td>13.873016</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>5.636163</td>\n",
       "      <td>13.873016</td>\n",
       "      <td>338</td>\n",
       "      <td>874</td>\n",
       "      <td>2.518307</td>\n",
       "      <td>2</td>\n",
       "      <td>5.535986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.135097</td>\n",
       "      <td>9.573333</td>\n",
       "      <td>0.470752</td>\n",
       "      <td>4.017634</td>\n",
       "      <td>9.573333</td>\n",
       "      <td>220</td>\n",
       "      <td>717</td>\n",
       "      <td>2.291086</td>\n",
       "      <td>17</td>\n",
       "      <td>4.916817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will AI Replace Us or Work With Us?“Machine in...</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.107673</td>\n",
       "      <td>14.962963</td>\n",
       "      <td>0.272277</td>\n",
       "      <td>6.094096</td>\n",
       "      <td>14.962963</td>\n",
       "      <td>291</td>\n",
       "      <td>808</td>\n",
       "      <td>2.388614</td>\n",
       "      <td>12</td>\n",
       "      <td>5.244559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Blockchain for PaymentsReconciling with the fi...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>0.101952</td>\n",
       "      <td>12.459459</td>\n",
       "      <td>0.266811</td>\n",
       "      <td>5.090508</td>\n",
       "      <td>12.459459</td>\n",
       "      <td>154</td>\n",
       "      <td>461</td>\n",
       "      <td>2.383948</td>\n",
       "      <td>9</td>\n",
       "      <td>5.503825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>The future of InvestingWhat Is an Investment?\\...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>16.306122</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>6.599545</td>\n",
       "      <td>16.306122</td>\n",
       "      <td>255</td>\n",
       "      <td>798</td>\n",
       "      <td>2.346683</td>\n",
       "      <td>1</td>\n",
       "      <td>5.307395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Big Data Analytics in HealthcareQuality and af...</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.419408</td>\n",
       "      <td>4.434430</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>230</td>\n",
       "      <td>608</td>\n",
       "      <td>2.388158</td>\n",
       "      <td>2</td>\n",
       "      <td>5.228448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Business Analytics In The Healthcare IndustryA...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>26.857143</td>\n",
       "      <td>0.611702</td>\n",
       "      <td>10.987538</td>\n",
       "      <td>26.857143</td>\n",
       "      <td>163</td>\n",
       "      <td>376</td>\n",
       "      <td>2.726064</td>\n",
       "      <td>0</td>\n",
       "      <td>5.826630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.095890</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>8.306452</td>\n",
       "      <td>0.316505</td>\n",
       "      <td>3.449183</td>\n",
       "      <td>8.306452</td>\n",
       "      <td>180</td>\n",
       "      <td>515</td>\n",
       "      <td>2.419417</td>\n",
       "      <td>8</td>\n",
       "      <td>5.148148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  Positive Score  \\\n",
       "0    AI in healthcare to Improve Patient OutcomesIn...              66   \n",
       "1    What if the Creation is Taking Over the Creato...              60   \n",
       "2    What Jobs Will Robots Take From Humans in The ...              66   \n",
       "3    Will Machine Replace The Human in the Future o...              69   \n",
       "4    Will AI Replace Us or Work With Us?“Machine in...              61   \n",
       "..                                                 ...             ...   \n",
       "109  Blockchain for PaymentsReconciling with the fi...              21   \n",
       "110  The future of InvestingWhat Is an Investment?\\...              39   \n",
       "111  Big Data Analytics in HealthcareQuality and af...              28   \n",
       "112  Business Analytics In The Healthcare IndustryA...              36   \n",
       "113  Challenges and Opportunities of Big Data in He...              33   \n",
       "\n",
       "     negative score  polarity score  subjectivity score  \\\n",
       "0                34        0.320000            0.098039   \n",
       "1                37        0.237113            0.159278   \n",
       "2                36        0.294118            0.116705   \n",
       "3                28        0.422680            0.135097   \n",
       "4                26        0.402299            0.107673   \n",
       "..              ...             ...                 ...   \n",
       "109              26       -0.106383            0.101952   \n",
       "110              14        0.471698            0.066333   \n",
       "111              47       -0.253333            0.123355   \n",
       "112               4        0.800000            0.106383   \n",
       "113              40       -0.095890            0.141748   \n",
       "\n",
       "     average sentence length  Percentage of Complex_words  fog index  \\\n",
       "0                  20.400000                     0.176471   8.230588   \n",
       "1                   9.515625                     0.622332   4.055183   \n",
       "2                  13.873016                     0.217391   5.636163   \n",
       "3                   9.573333                     0.470752   4.017634   \n",
       "4                  14.962963                     0.272277   6.094096   \n",
       "..                       ...                          ...        ...   \n",
       "109                12.459459                     0.266811   5.090508   \n",
       "110                16.306122                     0.192741   6.599545   \n",
       "111                10.666667                     0.419408   4.434430   \n",
       "112                26.857143                     0.611702  10.987538   \n",
       "113                 8.306452                     0.316505   3.449183   \n",
       "\n",
       "     Average Number of Words Per Sentence  complex words  word count  \\\n",
       "0                               20.400000            379        1020   \n",
       "1                                9.515625            190         609   \n",
       "2                               13.873016            338         874   \n",
       "3                                9.573333            220         717   \n",
       "4                               14.962963            291         808   \n",
       "..                                    ...            ...         ...   \n",
       "109                             12.459459            154         461   \n",
       "110                             16.306122            255         798   \n",
       "111                             10.666667            230         608   \n",
       "112                             26.857143            163         376   \n",
       "113                              8.306452            180         515   \n",
       "\n",
       "     syllables per word  personal pronouns count  average word length  \n",
       "0              2.496078                        1             5.801782  \n",
       "1              2.215107                        6             5.007047  \n",
       "2              2.518307                        2             5.535986  \n",
       "3              2.291086                       17             4.916817  \n",
       "4              2.388614                       12             5.244559  \n",
       "..                  ...                      ...                  ...  \n",
       "109            2.383948                        9             5.503825  \n",
       "110            2.346683                        1             5.307395  \n",
       "111            2.388158                        2             5.228448  \n",
       "112            2.726064                        0             5.826630  \n",
       "113            2.419417                        8             5.148148  \n",
       "\n",
       "[114 rows x 14 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(0,len(d3)):\n",
    "    text=d3.iloc[i].values[0]\n",
    "    txt=[] #reset \n",
    "    txt.append(text)\n",
    "    # use nltk.sent_tokenize to split the text into sentences and count them\n",
    "    num_sentences = len(nltk.sent_tokenize(str(txt)))\n",
    "    cleaned_texts = []  # reset cleaned_texts for each text\n",
    "    cleaned_text = clean_text(text)  #object to function call\n",
    "    cleaned_texts.extend(cleaned_text) \n",
    "    clean_word_length = len(cleaned_texts)  #number of words after removing stopwords aka cleaning\n",
    "    pos_score=positive_score(cleaned_texts, pos_dict)\n",
    "    neg_score=negative_score(cleaned_texts,neg_dict)\n",
    "    polarity_score=pol_score(pos_score, neg_score)\n",
    "    subj_score=subjectivity_score(pos_score, neg_score,clean_word_length)\n",
    "    average_sentence_length=avg_sent_len(num_sentences,clean_word_length)\n",
    "    percent_complex=percentage_complex_words(cleaned_texts,clean_word_length)\n",
    "    fog_index=f_ind(average_sentence_length,percent_complex)\n",
    "    Average_Number_of_Words_Per_Sentence=avg_words_per_sent(clean_word_length,num_sentences)\n",
    "    complex_words=count_complex_words(cleaned_texts)\n",
    "    word_count=w_count(cleaned_texts)\n",
    "    syllables_per_word=syllableperword(cleaned_texts)\n",
    "    personal_pronouns_count=pronouns_count(text)\n",
    "    average_word_length=avg_word_len(txt)\n",
    "    # Append the results to the list\n",
    "    results.append([text, pos_score,neg_score,polarity_score,subj_score,average_sentence_length,percent_complex,fog_index,Average_Number_of_Words_Per_Sentence,complex_words,word_count,syllables_per_word,personal_pronouns_count,average_word_length])\n",
    "# Create a new DataFrame from the results list\n",
    "df_results = pd.DataFrame(results, columns=['text', 'Positive Score','negative score','polarity score','subjectivity score','average sentence length','Percentage of Complex_words','fog index','Average Number of Words Per Sentence','complex words','word count','syllables per word','personal pronouns count','average word length'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c31b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, df_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6b2ec86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel('output_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c6e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
